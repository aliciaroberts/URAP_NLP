{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc48b50b-c499-4aa8-b862-93bdfb2a696f",
   "metadata": {},
   "source": [
    "## Baby's First NLP Model\n",
    "\n",
    "**Start Date: 11/13/2024**\n",
    "\n",
    "Alicia Roberts\n",
    "\n",
    "\n",
    "_this is inspired by the spam-ham lab from data 100 that I completed last semester: using a bunch of text entries that have been labeled a spam email or a ham email, predict if an unlabeled email is either spam or ham after training a model. I think this will be a good start to this project as it is of very similar structure but instead of classifying emails, we are classifying if the occurences of 一世と二世　are true occurences or incorrect occurences for generational terms_\n",
    "\n",
    "\n",
    "**Thinking:** this model will be trained on a certain phrase or set of phrases and if you plug in a text, it will look for that word or phrase and tell you if it is in the context that you want it to be. For Sora's project, I think implementing a sentiment analysis would be really cool, but might be too difficult in practice with the current resources we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4484e8-6c73-4928-9da4-607c3fdcc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "\n",
    "\n",
    "# add Japanese language processing here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205f51bd-e87a-4633-af12-6be2ba155851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data: \n",
    "\n",
    "# the entire labelled data set: \n",
    "\n",
    "\n",
    "\n",
    "# describe it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8311125f-6346-4055-b515-2859b5516b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now clean it and split it into training, test, and validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ddd59-624f-42ac-9a47-858670a0bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
