{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c4c870-86f2-4048-83c1-94d587bd9367",
   "metadata": {},
   "source": [
    "# Sample Data Maker\n",
    "\n",
    "this creates a sample data set that is in the format ready to be classified by a translator. thank you !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1977bb97-a9a7-4397-9355-2f4c65fdabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a396d7b-d9ae-48dd-8227-f9e3dfef4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../../data/output_5000_redo.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3563bc15-e14a-4282-81e1-92280506d598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>linkWithDate</th>\n",
       "      <th>numWords</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>pdfName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=jan19360...</td>\n",
       "      <td>https://hojishinbun.hoover.org/en/newspapers/j...</td>\n",
       "      <td>5</td>\n",
       "      <td>滅念祀迎獸轚鼴罾鐮 81 帝 1 世を黏レゎそれ —№ 11 にこ # は於 &amp; しヤやニル...</td>\n",
       "      <td>jan_19360710_0019.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=kam19350...</td>\n",
       "      <td>https://hojishinbun.hoover.org/en/newspapers/k...</td>\n",
       "      <td>7</td>\n",
       "      <td>「 ，！ 一 ： こ匿 - — 511. :.?-&lt;-€¢€1—\"--#118*141( -...</td>\n",
       "      <td>kam_19350811_0003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=kam19420...</td>\n",
       "      <td>https://hojishinbun.hoover.org/en/newspapers/k...</td>\n",
       "      <td>5</td>\n",
       "      <td>一世二世の失業者は ’： 一 1^ ノ至急市協へ報吿せょ一 ：1 - ”£2” 日本人救濟の...</td>\n",
       "      <td>kam_19420128_0003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=jan19410...</td>\n",
       "      <td>https://hojishinbun.hoover.org/en/newspapers/j...</td>\n",
       "      <td>6</td>\n",
       "      <td>號ニ十六百七千四万一第 當太和 3 声では開菜一一一却年 2.. ' と I て來る四 ：：...</td>\n",
       "      <td>jan_19410107_0005.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=kam19350...</td>\n",
       "      <td>https://hojishinbun.hoover.org/en/newspapers/k...</td>\n",
       "      <td>2</td>\n",
       "      <td>ジブラルタルとスュズ運河 ， 藤丼整 霉とな 〇 先が ^ ブチルタル線杯か 6111 8 ...</td>\n",
       "      <td>kam_19350922_0002.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://hojishinbun.hoover.org/?a=d&d=jan19360...   \n",
       "1  https://hojishinbun.hoover.org/?a=d&d=kam19350...   \n",
       "2  https://hojishinbun.hoover.org/?a=d&d=kam19420...   \n",
       "3  https://hojishinbun.hoover.org/?a=d&d=jan19410...   \n",
       "4  https://hojishinbun.hoover.org/?a=d&d=kam19350...   \n",
       "\n",
       "                                        linkWithDate  numWords  \\\n",
       "0  https://hojishinbun.hoover.org/en/newspapers/j...         5   \n",
       "1  https://hojishinbun.hoover.org/en/newspapers/k...         7   \n",
       "2  https://hojishinbun.hoover.org/en/newspapers/k...         5   \n",
       "3  https://hojishinbun.hoover.org/en/newspapers/j...         6   \n",
       "4  https://hojishinbun.hoover.org/en/newspapers/k...         2   \n",
       "\n",
       "                                          paragraphs                pdfName  \n",
       "0  滅念祀迎獸轚鼴罾鐮 81 帝 1 世を黏レゎそれ —№ 11 にこ # は於 & しヤやニル...  jan_19360710_0019.pdf  \n",
       "1  「 ，！ 一 ： こ匿 - — 511. :.?-<-€¢€1—\"--#118*141( -...  kam_19350811_0003.pdf  \n",
       "2  一世二世の失業者は ’： 一 1^ ノ至急市協へ報吿せょ一 ：1 - ”£2” 日本人救濟の...  kam_19420128_0003.pdf  \n",
       "3  號ニ十六百七千四万一第 當太和 3 声では開菜一一一却年 2.. ' と I て來る四 ：：...  jan_19410107_0005.pdf  \n",
       "4  ジブラルタルとスュズ運河 ， 藤丼整 霉とな 〇 先が ^ ブチルタル線杯か 6111 8 ...  kam_19350922_0002.pdf  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766642d0-91e5-4aa0-b325-0ee696c69382",
   "metadata": {},
   "source": [
    "## Prep the Data to be sent for translation: \n",
    "\n",
    "Break up into the columns we want (link, numwords, paragraphs) and then add a label column that will be changed later by the translators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59a6d14d-19fe-45bf-bfb9-d9ab69010b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['numWords']>0]\n",
    "data_cleaned = data[['link','numWords','paragraphs']]\n",
    "# labels_col = np.zeros(int(data_cleaned.shape[0])) - 99 # -99 so we know if it was labelled yet \n",
    "# data_cleaned = data_cleaned.assign(**{'label': labels_col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b0439be-e6fa-49d6-be5f-28edc78ec3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>numWords</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=tnw19310...</td>\n",
       "      <td>1</td>\n",
       "      <td>诚六廿 ^: 八午家箱 ？ 0 奶 日系市民の副檢事月偉千ドルを受く市民官吏中のタツブを切る...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=kam19320...</td>\n",
       "      <td>1</td>\n",
       "      <td>， 本學生にこの正義觀敎室で親日高唱非常識な排日敎師をやリこめる二 ， 蜜林某小學校の話 I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=nws19360...</td>\n",
       "      <td>1</td>\n",
       "      <td>漦九十九对三第 閱斩ロ輞荩 # 餅 II 際 : こニ ^ 麵女一塲技競泳水會大オンリルべ一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=nws19401...</td>\n",
       "      <td>1</td>\n",
       "      <td>( 电京卜 ： れは闻既じ去る九日御成年式を取げさせられた東久邇宮彰常 ： 土殿下にはよあふ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=jan19290...</td>\n",
       "      <td>1</td>\n",
       "      <td>0 ¢8 ” み霣ニ供 ， 一 - 、 〇 六西故弗の鑛山女王自動米衝突 7 落命飲 31 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=nis19370...</td>\n",
       "      <td>21</td>\n",
       "      <td>. 一 「 爲讀港寄書 、 18111113118188— 自 E 『 ユ愿 446 戋 【...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=ksp19400...</td>\n",
       "      <td>23</td>\n",
       "      <td>為號八十七百七千一第報新哇加日一月一年五十和昭 たびあぢそく ^. 旅はよいもの味なもの ，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=jan19380...</td>\n",
       "      <td>24</td>\n",
       "      <td>本嗍鼇に就ぃて其の寅默旳方法を猶ずる C 先き立つて先つ £ 鼠を二 0 に $ 黻し . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=tht19470...</td>\n",
       "      <td>25</td>\n",
       "      <td>me &amp; 厂 ・ ! ・ ー ー ー ー — 一 新日本の活舞臺に , 躍進の二世群像 … ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>https://hojishinbun.hoover.org/?a=d&amp;d=mas19391...</td>\n",
       "      <td>26</td>\n",
       "      <td>日九辻月二十年九三九一聞新哇馬 I マゥィに於ける短歌の隆 : 盛は月を追うて成果しつつ一あ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   link  numWords  \\\n",
       "2746  https://hojishinbun.hoover.org/?a=d&d=tnw19310...         1   \n",
       "2001  https://hojishinbun.hoover.org/?a=d&d=kam19320...         1   \n",
       "2002  https://hojishinbun.hoover.org/?a=d&d=nws19360...         1   \n",
       "2003  https://hojishinbun.hoover.org/?a=d&d=nws19401...         1   \n",
       "2004  https://hojishinbun.hoover.org/?a=d&d=jan19290...         1   \n",
       "...                                                 ...       ...   \n",
       "4166  https://hojishinbun.hoover.org/?a=d&d=nis19370...        21   \n",
       "4163  https://hojishinbun.hoover.org/?a=d&d=ksp19400...        23   \n",
       "4171  https://hojishinbun.hoover.org/?a=d&d=jan19380...        24   \n",
       "4195  https://hojishinbun.hoover.org/?a=d&d=tht19470...        25   \n",
       "4188  https://hojishinbun.hoover.org/?a=d&d=mas19391...        26   \n",
       "\n",
       "                                             paragraphs  \n",
       "2746  诚六廿 ^: 八午家箱 ？ 0 奶 日系市民の副檢事月偉千ドルを受く市民官吏中のタツブを切る...  \n",
       "2001  ， 本學生にこの正義觀敎室で親日高唱非常識な排日敎師をやリこめる二 ， 蜜林某小學校の話 I...  \n",
       "2002  漦九十九对三第 閱斩ロ輞荩 # 餅 II 際 : こニ ^ 麵女一塲技競泳水會大オンリルべ一...  \n",
       "2003  ( 电京卜 ： れは闻既じ去る九日御成年式を取げさせられた東久邇宮彰常 ： 土殿下にはよあふ...  \n",
       "2004  0 ¢8 ” み霣ニ供 ， 一 - 、 〇 六西故弗の鑛山女王自動米衝突 7 落命飲 31 ...  \n",
       "...                                                 ...  \n",
       "4166  . 一 「 爲讀港寄書 、 18111113118188— 自 E 『 ユ愿 446 戋 【...  \n",
       "4163  為號八十七百七千一第報新哇加日一月一年五十和昭 たびあぢそく ^. 旅はよいもの味なもの ，...  \n",
       "4171  本嗍鼇に就ぃて其の寅默旳方法を猶ずる C 先き立つて先つ £ 鼠を二 0 に $ 黻し . ...  \n",
       "4195  me & 厂 ・ ! ・ ー ー ー ー — 一 新日本の活舞臺に , 躍進の二世群像 … ...  \n",
       "4188  日九辻月二十年九三九一聞新哇馬 I マゥィに於ける短歌の隆 : 盛は月を追うて成果しつつ一あ...  \n",
       "\n",
       "[2950 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.sort_values('numWords', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee013f1c-2a32-4a1d-bb9b-24c234695c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data = data_cleaned, x = 'numWords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1d6f0a-1224-4d78-a65f-fedf1662271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a data table that shows how many data points only have one hit: \n",
    "# data_cleaned.groupby('numWords').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a72761f-b3c5-49af-8c11-9c8e6e5d110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions: \n",
    "\n",
    "def make_hit_arrays(string, hit, r):\n",
    "    '''return a shortened version of STRING that is centered around HIT with R characters on each side of it\n",
    "    STRING: any string\n",
    "    HIT: any word\n",
    "    returns:\n",
    "    STRING wihout HIT, N: any positive integer that is the location of HIT in STRING. will return the first occurence of the first character of HIT'''\n",
    "    ns = [] # this means there is no occurence of HIT if empty\n",
    "    hit_strings = []\n",
    "    \n",
    "    if (hit in string): # first see that HIT is actually in STRING to avoid errors\n",
    "        size_hit = len(hit) # how many characters to examine at once \n",
    "        \n",
    "        for n in range(len(string) - size_hit): # itterate through STRING until you reach HIT\n",
    "            \n",
    "            if string[n:n+size_hit] == hit: # iterating till we reach HIT\n",
    "                ns.append(n)\n",
    "                hit_strings.append(string[max(0,n - r): min(n + r, len(string))])\n",
    "    return hit_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c98cc6b-cf22-4e38-bdd0-e20e098d1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_num_words(data, num_words = [1], num_samples =100):\n",
    "    '''INPUT: Data: a data frame with the assumed column labls of link, numWords, paragraphs\n",
    "        num_words: list-like of valid numWords in each data sample of the hit phrase\n",
    "        num_samples: the number of data points you want back to categorize\n",
    "    OUTPUT: a data frame that is ready to be translated'''\n",
    "    \n",
    "     # make an array of num_words \n",
    "    label_data = data[data['numWords'].isin(num_words)] # only keeps data that has the num words we want\n",
    "    sample_table = label_data.sample(num_samples, random_state = 42) # sample the data randomly num_samples times \n",
    "\n",
    "\n",
    "    # add the label column: \n",
    "    labels_col = np.zeros(int(sample_table.shape[0])) - 99 # -99 so we know if it was labelled yet \n",
    "    data_final = sample_table.assign(**{'label': labels_col})\n",
    "\n",
    "    return data_final\n",
    "        \n",
    "def split_data_by_num_words(data, hit = '二世', r = 25):\n",
    "    '''given DATA with column numWords, split the data into rows of hit arrays \n",
    "    that share all column information except for paragraphs, which is now a split version, with numWords = 1. Then remove the original rows'''\n",
    "    new_data_points = [] # an array of arrays that have the column values for each new data point \n",
    "\n",
    "    data_index = np.array([]) # an array that contains the original index value of the new data points \n",
    "    c = 0\n",
    "    # for s in data['Paragraphs'].values:\n",
    "    #     new_strings = make_hit_arrays(s, hit = '二世', r = r)\n",
    "    #     data_index = np.append(data_index, np.zeros(len(new_strings)) + c)\n",
    "    #     new_data_points.extend(new_strings)\n",
    "    #     c += 1\n",
    "    for s in data.values:\n",
    "        hit_arrs = make_hit_arrays(s[2], hit = hit, r = r)\n",
    "        for h in hit_arrs:\n",
    "            new_data_points.append([s[0], 1, h]) # oiginal link, now only 1 numwords, new hit array, same label \n",
    "    \n",
    "    new_data = pd.DataFrame(data = new_data_points, columns = data.columns)# the final data frame with cleaned arrays with hits at the center \n",
    "    return new_data\n",
    "\n",
    "def get_data_by_years(data, years = ['1923','1924','1925'], num_samples = 100):\n",
    "    '''do the same thing as getting numwords data but now do it by getting the year out from the link\n",
    "    YEARS must be a string'''\n",
    "    year_arr = data['link'].str.extract(pat = r'(19\\d\\d)')\n",
    "    data_with_year = data.assign(**{'year':year_arr})\n",
    "    data_valid = data_with_year[data_with_year['year'].isin(years)].sample(num_samples, random_state = 42)\n",
    "    return data_valid.drop('year', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11c9a4a7-7c3d-49c3-baf2-a0adde9a601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1920s = get_data_by_years(data_cleaned, years = ['1920','1921','1922','1923','1924','1925', '1926', '1927','1928', '1929'])\n",
    "\n",
    "data_1920s_split = split_data_by_num_words(data_1920s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f6ffd00-3551-4c13-b714-0e92c088dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_data = data_cleaned[data_cleaned['numWords'] == 1]\n",
    "# label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "794e10e3-cdd6-4ebb-8dc9-422011d009d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_table = label_data.sample(100, random_state = 42)\n",
    "# sample_indeces = sample_table.index\n",
    "# sample_table = sample_table.drop('numWords', axis = 1).reset_index() # we don't need this since we know they all only have 1 and its training data\n",
    "\n",
    "# # and then since we want to make sure we can keep the \n",
    "# # training data separate from the test data, we should take these data points out of the big data file, which is why we picked the random state we did\n",
    "# sample_table.head(), sample_indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a5519e5f-7bfd-478a-a121-3b0bbc386681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99., -99., -99., -99., -99., -99., -99., -99., -99.,\n",
       "       -99., -99., -99.])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_arr = np.zeros(data_1920s_split.shape[0]) - 99\n",
    "\n",
    "labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "70e12e21-1e2b-4f15-a9ae-727396478c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_table_1920s = data_1920s_split.assign(**{'label': labels_arr}).drop('numWords', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "024da875-f242-4b3b-ad58-6804e3330671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now to export!\n",
    "from pathlib import Path  \n",
    "filepath = Path('C:\\\\Users\\\\alica\\\\Documents\\\\URAP\\\\data\\\\training_data_sample2.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  # makes a directory for the CSV file to be written into \n",
    "sample_table_1920s.to_csv(filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdabc69-4060-4eb3-b796-2030a4ecb6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
